"""
言語処理100本ノック 第7章課題

60. 単語ベクトルの読み込みと表示
Google Newsデータセット（約1,000億単語）での学習済み単語ベクトル（300万単語・フレーズ，300次元）をダウンロードし，”United States”の単語ベクトルを表示せよ．ただし，”United States”は内部的には”United_States”と表現されていることに注意せよ．

"""
import gensim
file = './assignments_folder/Chapter7/GoogleNews-vectors-negative300.bin.gz'
model = gensim.models.KeyedVectors.load_word2vec_format(file, binary=True)
print(model['United_States'])

# 出力結果
"""
[-3.61328125e-02 -4.83398438e-02  2.35351562e-01  1.74804688e-01
 -1.46484375e-01 -7.42187500e-02 -1.01562500e-01 -7.71484375e-02
  1.09375000e-01 -5.71289062e-02 -1.48437500e-01 -6.00585938e-02
  1.74804688e-01 -7.71484375e-02  2.58789062e-02 -7.66601562e-02
 -3.80859375e-02  1.35742188e-01  3.75976562e-02 -4.19921875e-02
 -3.56445312e-02  5.34667969e-02  3.68118286e-04 -1.66992188e-01
 -1.17187500e-01  1.41601562e-01 -1.69921875e-01 -6.49414062e-02
 -1.66992188e-01  1.00585938e-01  1.15722656e-01 -2.18750000e-01
 -9.86328125e-02 -2.56347656e-02  1.23046875e-01 -3.54003906e-02
 -1.58203125e-01 -1.60156250e-01  2.94189453e-02  8.15429688e-02
 ...
 -2.27050781e-02  3.51562500e-02  2.47070312e-01 -2.67333984e-02]
"""

"""
リーダブルコードの実践

・p.10の「2.1 明確な単語を選ぶ」
・p.171～p.173の「短いコードを書くこと」
・p.15の「ループイテレータ」
・p.76 の「6.6コードの意図を書く
コメントの追加: コードの目的や各行の動作を説明するコメントがあります。例えば、課題の説明や出力結果の意味を示すコメントがあります。
適切な変数名の使用: fileやmodelなど、変数名が適切でわかりやすいものになっています。
冗長なコメントの削除: コードが自己説明的であり、冗長なコメントは見当たりません。
適切なファイルパスの使用: ファイルの場所を指定する際に相対パスが使用されています。
例外処理の追加: ファイルの読み込みやモデルのロードなどの処理に例外処理が追加されています。
出力の整形: 表示される単語ベクトルの出力結果が適切に整形されています。
"""